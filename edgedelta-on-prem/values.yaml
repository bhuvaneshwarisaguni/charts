fullNameOverride: ""
dnsSuffix: "svc.cluster.local"
repository: "gcr.io/edgedelta"
storageClassName: ""
usingOpenShift: false # Should be true for OpenShift for smooth procedure

# This should be enabled and edited for secure clusters such as OpenShift/EKS
# podSecurityContext:
#   runAsUser: 1000

openFaas: # Valid for all deployment types
  enabled: true
  minRehydrationCount: 1
  minConfigTestCount: 1
  isFullDeployment: true
  proLicense: ""

ingress:
  enabled: true

clusterIssuer:
  enabled: true
  letsEncryptEmail: ""

  namespaceLabeler:
    image: bitnami/kubectl:1.22.9

api:
  enabled: true
  useServiceAccount: true
  masterSecret: "" # It will use a randomly-generated UUIDv4 if not set

  # When rehydration poller or configtest poller enabled without a token, initializer component will create an API token for these components.
  # In this case both of these tools will use the same token.

  # Users can also supply the tokens for these components via `token` option, it is also considered for both of the tools also.
  # So this generated token should have the following permissions
  # Rehydration - All Current and Future Rehydrations - Write
  # Integration - All Current and Future Rehydrations - Read
  # Agent Configurations - All Current and Future Agent Configurations - Read
  token: ""
  tokenSecretName: "ed-api-token"

  port: 4444
  hostName: ""
  corsOverrides: []
  # This should be enabled and edited for secure clusters such as OpenShift/EKS
  # podSecurityContext:
  #   runAsUser: 1000

  replicaCount: 4
  resources:
    limits:
      cpu: 1024m
      memory: 2048Mi
    requests:
      cpu: 512m
      memory: 256Mi

  login:
    disableAuthentication: false
    saml:
      enabled: false
      redirectUrl: ""
      alwaysUseSaml: false

app:
  enabled: true
  useServiceAccount: true
  port: 5555
  hostName: ""
  overrideApiUrl: "" # Default is https://<api_host_name>, however if this field is not empty, we will override api url with given one
  # This should be enabled and edited for secure clusters such as OpenShift/EKS
  # podSecurityContext:
  #   runAsUser: 1000

  replicaCount: 3
  resources:
    limits:
      cpu: 200m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 20Mi

batchJobs:
  useServiceAccount: true
  # This should be enabled and edited for secure clusters such as OpenShift/EKS
  # podSecurityContext:
  #   runAsUser: 1000

  agentDownDetector:
    enabled: true
    cronString: "*/5 * * * *"
    metricPort: 8181
    window: "5m"
    offset: "1m"
    timeout: "10m"
  configValidation:
    enabled: true
    cronString: "0 16 * * *"
    timeout: "1h"
  correlatedSignal:
    enabled: true
    cronString: "*/5 * * * *"
    window: "15m"
    offset: "1m"
    timeout: "5m"
  crashLoopDetector:
    enabled: true
    cronString: "*/5 * * * *"
    metricPort: 8181
    window: "5m"
    offset: "1m"
    timeout: "10m"
  metricAlert:
    enabled: true
    cronString: "*/5 * * * *"
    metricPort: 8181
    window: "5m"
    offset: "1m"
    timeout: "5m"
  notifyFindings:
    enabled: true
    cronString: "*/5 * * * *"
    window: "5m"
    offset: "2m"
    timeout: "3m"
  patternCheck:
    enabled: true
    # At every 10th minute from 2 through 59: xx:02,xx:12,xx:22 etc..
    cronString: "2-59/10 * * * *"
    window: "1h"
    offset: "1m"
    timeout: "10m"
    concurrency: 20
  patternSkyline:
    enabled: true
    # At every 10th minute from 2 through 59: xx:02,xx:12,xx:22 etc..
    cronString: "1-59/5 * * * *"
    window: "15m"
    offset: "1m"
    timeout: "5m"
  sourceVersionChange:
    enabled: true
    cronString: "*/5 * * * *"
    metricPort: 8181
    window: "5m"
    offset: "1m"
    timeout: "5m"
  streamerFailureDetector:
    enabled: true
    cronString: "*/10 * * * *"
    window: "10m"
    offset: "1m"
    timeout: "10m"

rehydration:
  orgId: ""
  mode: "prod"
  pushBatchSize: "10000"
  apiEndpoint: "" # It should be empty for "full" deployment mode. Default is https://api.edgedelta.com
  memoryLimit: 16 # In terms of GB
  goGC: 20 # It designates the aggressiveness of the garbage collection. Less is more aggressive. Default it 20.
  concurrency: 4 # It affects number of files that would be downloaded concurrently, default is 4
  agentTagsFilter: "" # Comma separated list of agent tags to perform rehydration

  cpuRequest: 1000m
  cpuLimit: 2000m

  pollerOptions: # Only valid if deployment mode is "only_rehydration"
    enabled: false
    useServiceAccount: true
    pollInterval: 10s
    # This should be enabled and edited for secure clusters such as OpenShift/EKS
    # podSecurityContext:
    #   runAsUser: 1000

    resources:
      limits:
        cpu: 200m
        memory: 200Mi
      requests:
        cpu: 100m
        memory: 100Mi

  handlerOptions: # only valid if deployment mode is "only_rehydration"
    enabled: false
    useServiceAccount: true
    clickhouseRhConnection: ""
    port: 8080
    replicaCount: 1
    # This should be enabled and edited for secure clusters such as OpenShift/EKS
    # podSecurityContext:
    #   runAsUser: 1000

    cpuRequest: 1000m
    cpuLimit: 2000m

clickhouse:
  enabled: false
  useServiceAccount: false
  image: clickhouse/clickhouse-server:23.2-alpine
  shardsCount: 1
  resources:
    limits:
      cpu: 2000m
      memory: 8Gi
    requests:
      cpu: 1500m
      memory: 8Gi
  # This should not exceed the memory limit
  maxMemoryUsage: 8000000000
  # This should be enabled and edited for secure clusters such as OpenShift/EKS
  # podSecurityContext:
  #   runAsUser: 1000
  keeperResources:
    limits:
      cpu: 1
      memory: 2Gi
    requests:
      cpu: 1
      memory: 1Gi

configtest:
  orgId: ""
  mode: "prod"
  apiEndpoint: "" # It should be empty for "full" deployment mode. Default is https://api.edgedelta.com
  agentTagsFilter: "" # Comma separated list of agent tags to perform configtest

  pollerOptions:
    enabled: false
    useServiceAccount: true
    pollInterval: 5s
    # This should be enabled and edited for secure clusters such as OpenShift/EKS
    # podSecurityContext:
    #   runAsUser: 1000

    resources:
      limits:
        cpu: 200m
        memory: 200Mi
      requests:
        cpu: 100m
        memory: 100Mi

  handlerOptions:
    enabled: false
    useServiceAccount: true
    port: 8080
    replicaCount: 1
    memoryLimit: 1 # In terms of GB
    # This should be enabled and edited for secure clusters such as OpenShift/EKS
    # podSecurityContext:
    #   runAsUser: 1000

    cpuRequest: 100m
    cpuLimit: 200m

initializer:
  enabled: true
  useServiceAccount: true
  # This should be enabled and edited for secure clusters such as OpenShift/EKS
  # podSecurityContext:
  #   runAsUser: 1000

  accessKeyIdName: "ed-database-access-key-id"
  secretKeyName: "ed-database-secret-key"
  configMapName: "ed-bootstrap-status"

  samlSubjectName: "ed-on-prem-org.com" # Certificate CN, SAN
  samlOrgName: "ed-on-prem-org" # Certificate Organization
  samlKeyName: "saml-key"
  samlCertName: "saml-cert"
  samlMetadataUrl: ""
  samlDomain: ""
  samlSkipSSLVerify: false # default is false

  # To be able to use elasticsearch some resources must be created. 
  #Â If this is set to true, those resources must be created manually.
  # To create them from code, we need create index/manage index privileges. 
  # Customers may choose to do these operations manually instead, by providing true to this flag.
  skipElasticsearchResourceCreation: false

  provisionOrgID: "" # if set an organization will be provisioned with this id

  resources:
    limits:
      cpu: 200m
      memory: 200Mi
    requests:
      cpu: 100m
      memory: 100Mi

database:
  dynamodb:
    image: edgedelta/datastore:v0.1.1
    enabled: false
    useServiceAccount: true
    # This should be enabled and edited for secure clusters such as OpenShift/EKS
    # podSecurityContext:
    #   runAsUser: 1000

    resources:
      limits:
        cpu: 400m
        memory: 2Gi
      requests:
        cpu: 200m
        memory: 1Gi

    storageResources:
      requests:
        storage: 10Gi

  # Rest is the configuration for third party dependencies and Helm charts
  scylladb:
    image: scylladb/scylla:4.6.3
    enabled: true
    useServiceAccount: true
    useDeveloperMode: false
    # This should be enabled and edited for secure clusters such as OpenShift/EKS
    # podSecurityContext:
    #   runAsUser: 1000

    useNonRoot:
      enabled: false
      image: gcr.io/edgedelta/scylla-non-root:4.6.3 # or edgedelta/scylla-non-root:4.6.3

    resources:
      limits:
        cpu: 2000m
        memory: 6Gi
      requests:
        cpu: 1000m
        memory: 3Gi

    storageResources:
      requests:
        storage: 10Gi

    config: |
      num_tokens: 256
      commitlog_sync: periodic
      commitlog_sync_period_in_ms: 10000
      commitlog_segment_size_in_mb: 32
      seed_provider:
        - class_name: org.apache.cassandra.locator.SimpleSeedProvider
          parameters:
            - seeds: "127.0.0.1"
      listen_address: localhost
      native_transport_port: 9042
      native_shard_aware_transport_port: 19042
      read_request_timeout_in_ms: 5000
      write_request_timeout_in_ms: 2000
      cas_contention_timeout_in_ms: 1000
      endpoint_snitch: SimpleSnitch
      alternator_enforce_authorization: true
      rpc_address: localhost
      rpc_port: 9160
      api_address: localhost
      api_port: 10000
      batch_size_warn_threshold_in_kb: 128
      batch_size_fail_threshold_in_kb: 1024
      partitioner: org.apache.cassandra.dht.Murmur3Partitioner
      commitlog_total_space_in_mb: -1
      murmur3_partitioner_ignore_msb_bits: 12

    nonRootConfigExtras: |
      workdir: /opt/scylladb/scylla
      data_file_directories:
        - /opt/scylladb/scylla/data/scylladata
      commitlog_directory: /opt/scylladb/scylla/commitlog
      hints_directory: /opt/scylladb/scylla/hints
      view_hints_directory: /opt/scylladb/scylla/view_hints

influxdb:
  enabled: false
  useServiceAccount: true
  # This should be enabled and edited for secure clusters such as OpenShift/EKS
  # podSecurityContext:
  #   runAsUser: 1000

  image:
    repository: bitnami/influxdb
    tag: 2.4.0

  port: 8086
  # Required if agents will use influx outside of cluster.
  hostName: ""
  # Sets the retention period for influx metric bucket. Default retention period is 7 days. 
  retentionPeriodInDays: 7

  resources:
    limits:
      cpu: 2000m
      memory: 6Gi
    requests:
      cpu: 1000m
      memory: 3Gi

  persistence:
    storageResources:
      requests:
        storage: 10Gi
    mountPath: /bitnami/influxdb

  adminUser:
    organization: "influxdata"
    bucket: "default"
    username: "admin"

elasticsearch:
  enabled: false
  useAsMetricBackend: false
  useServiceAccount: true
  # This should be enabled and edited for secure clusters such as OpenShift/EKS
  # podSecurityContext:
  #   runAsUser: 1000

  # Connect to already existing elastic instance
  connection:
    cloud_id: ""   # connection can be established using cloud_id or addresses
    addresses: "" # comma separated list

    token: ""    # authentication is done with token or username-password pair
    username: ""
    password: ""

    region: ""

    port: 9200 # elastic service port when image is used
    # Required if agents will use elastic outside of cluster and elastic image is enabled
    hostName: ""

  # when image is enabled, a password can be optionally provided in connection section to override default value ("elastic-password")
  # username will be automatically set to "elastic"
  # and the instance address will be http://elasticsearch-service.edgedelta-backend.svc.cluster.local:$port

  image:
    enabled: false # when enabled, a single node cluster elasticsearch with the provided resources in this section will be deployed.
    repository: elasticsearch
    tag: 8.5.0

    resources:
      limits:
        cpu: 2000m
        memory: 6Gi
      requests:
        cpu: 1000m
        memory: 3Gi

    storage: 16Gi

openfaas:
  # securityContext: true # This should be enabled and edited for secure clusters such as OpenShift
  functionNamespace: "openfaas-fn" # It should be renamed as helm namespace
  serviceType: "NodePort"
  basic_auth: false
  generateBasicAuth: false
  openfaasPro: false # Set to true when license is not empty
  ceScaling: false
  proScaler:
    image: ghcr.io/openfaasltd/autoscaler:0.2.0 # or edgedelta/openfaas-autoscaler:0.2.0
    enabled: false # Set to true when license is not empty
  faasIdler:
    image: ghcr.io/openfaas/faas-idler-pro:0.4.4 # or edgedelta/openfaas-faas-idler-pro:0.4.4
    enabled: false # Set to true when license is not empty
  oidcAuthPlugin:
    image: ghcr.io/openfaas/openfaas-oidc-plugin:0.5.1 # or edgedelta/openfaas-oidc-plugin:0.5.1
    enabled: false
  gateway:
    image: ghcr.io/openfaas/gateway:0.21.3 # or edgedelta/openfaas-gateway:0.21.3
    readTimeout: "1h5m"
    writeTimeout: "1h5m"
    upstreamTimeout: "1h" # Must be smaller than read/write_timeout
  basicAuthPlugin:
    image: ghcr.io/openfaas/basic-auth:0.21.1 # or edgedelta/openfaas-basic-auth:0.21.1
  faasnetes:
    image: ghcr.io/openfaas/faas-netes:0.14.1 # or edgedelta/openfaas-faas-netes:0.14.1
    readTimeout: "1h5m"
    writeTimeout: "1h5m"
  operator:
    image: ghcr.io/openfaas/faas-netes:0.14.1 # or edgedelta/openfaas-faas-netes:0.14.1
  queueWorkerPro:
    image: ghcr.io/openfaas/queue-worker-pro:0.1.0-rc5 # or edgedelta/openfaas-queue-worker-pro:0.1.0-rc5
    enabled: false # Set to true when license is not empty
  queueWorker:
    image: ghcr.io/openfaas/queue-worker:0.12.2 # or edgedelta/openfaas-queue-worker:0.12.2
    ackWait: "1h"
  prometheus:
    image: prom/prometheus:v2.11.0
  alertmanager:
    image: prom/alertmanager:v0.18.0
  nats:
    image: nats-streaming:0.22.0
    metrics:
      image: natsio/prometheus-nats-exporter:0.8.0
      enabled: false
  ingressOperator:
    image: ghcr.io/openfaas/ingress-operator:0.6.7 # or edgedelta/openfaas-ingress-operator:0.6.7
  autoscaler:
    enabled: false # Set to true when license is not empty
  clusterRole: false # Set to true when license is not empty
